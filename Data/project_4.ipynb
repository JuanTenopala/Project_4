{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import matplotlib.pyplot as plt\n",
    "#import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chardet.detect(open(\"./Summer-Olympic-medals-1976-to-2008.csv\", 'rb').read())['encoding']\n",
    "chardet.detect(open(\"./Summer-Olympic-medals-1976-to-2008.csv\", 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15433, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Summer-Olympic-medals-1976-to-2008.csv\", encoding=\"ISO-8859-1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"./Summer-Olympic-medals-1976-to-2008.csv\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Event</th>\n",
       "      <th>Athlete</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Event_gender</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>KÖHLER, Christa</td>\n",
       "      <td>Women</td>\n",
       "      <td>GDR</td>\n",
       "      <td>East Germany</td>\n",
       "      <td>W</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>KOSENKOV, Aleksandr</td>\n",
       "      <td>Men</td>\n",
       "      <td>URS</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>BOGGS, Philip George</td>\n",
       "      <td>Men</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>CAGNOTTO, Giorgio Franco</td>\n",
       "      <td>Men</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Italy</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>10m platform</td>\n",
       "      <td>WILSON, Deborah Keplar</td>\n",
       "      <td>Women</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>W</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15428</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>66 - 74kg</td>\n",
       "      <td>GUENOT, Christophe</td>\n",
       "      <td>Men</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15429</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>66 - 74kg</td>\n",
       "      <td>KVIRKELIA, Manuchar</td>\n",
       "      <td>Men</td>\n",
       "      <td>GEO</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15430</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>55 - 60kg</td>\n",
       "      <td>RAHIMOV, Vitaliy</td>\n",
       "      <td>Men</td>\n",
       "      <td>AZE</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15431</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>60 - 66kg</td>\n",
       "      <td>GUENOT, Steeve</td>\n",
       "      <td>Men</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>96 - 120kg</td>\n",
       "      <td>LOPEZ, Mijain</td>\n",
       "      <td>Men</td>\n",
       "      <td>CUB</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15433 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City    Year      Sport       Discipline           Event  \\\n",
       "0      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "1      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "2      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "3      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "4      Montreal  1976.0   Aquatics           Diving    10m platform   \n",
       "...         ...     ...        ...              ...             ...   \n",
       "15428   Beijing  2008.0  Wrestling  Wrestling Gre-R       66 - 74kg   \n",
       "15429   Beijing  2008.0  Wrestling  Wrestling Gre-R       66 - 74kg   \n",
       "15430   Beijing  2008.0  Wrestling  Wrestling Gre-R       55 - 60kg   \n",
       "15431   Beijing  2008.0  Wrestling  Wrestling Gre-R       60 - 66kg   \n",
       "15432   Beijing  2008.0  Wrestling  Wrestling Gre-R      96 - 120kg   \n",
       "\n",
       "                        Athlete Gender Country_Code        Country  \\\n",
       "0               KÖHLER, Christa  Women          GDR   East Germany   \n",
       "1           KOSENKOV, Aleksandr    Men          URS   Soviet Union   \n",
       "2          BOGGS, Philip George    Men          USA  United States   \n",
       "3      CAGNOTTO, Giorgio Franco    Men          ITA          Italy   \n",
       "4        WILSON, Deborah Keplar  Women          USA  United States   \n",
       "...                         ...    ...          ...            ...   \n",
       "15428        GUENOT, Christophe    Men          FRA         France   \n",
       "15429       KVIRKELIA, Manuchar    Men          GEO        Georgia   \n",
       "15430          RAHIMOV, Vitaliy    Men          AZE     Azerbaijan   \n",
       "15431            GUENOT, Steeve    Men          FRA         France   \n",
       "15432             LOPEZ, Mijain    Men          CUB           Cuba   \n",
       "\n",
       "      Event_gender   Medal  \n",
       "0                W  Silver  \n",
       "1                M  Bronze  \n",
       "2                M    Gold  \n",
       "3                M  Silver  \n",
       "4                W  Bronze  \n",
       "...            ...     ...  \n",
       "15428            M  Bronze  \n",
       "15429            M    Gold  \n",
       "15430            M  Silver  \n",
       "15431            M    Gold  \n",
       "15432            M    Gold  \n",
       "\n",
       "[15433 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Event</th>\n",
       "      <th>Athlete</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Event_gender</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>KÖHLER, Christa</td>\n",
       "      <td>Women</td>\n",
       "      <td>GDR</td>\n",
       "      <td>East Germany</td>\n",
       "      <td>W</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>KOSENKOV, Aleksandr</td>\n",
       "      <td>Men</td>\n",
       "      <td>URS</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>BOGGS, Philip George</td>\n",
       "      <td>Men</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>3m springboard</td>\n",
       "      <td>CAGNOTTO, Giorgio Franco</td>\n",
       "      <td>Men</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Italy</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Diving</td>\n",
       "      <td>10m platform</td>\n",
       "      <td>WILSON, Deborah Keplar</td>\n",
       "      <td>Women</td>\n",
       "      <td>USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>W</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15428</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>66 - 74kg</td>\n",
       "      <td>GUENOT, Christophe</td>\n",
       "      <td>Men</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15429</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>66 - 74kg</td>\n",
       "      <td>KVIRKELIA, Manuchar</td>\n",
       "      <td>Men</td>\n",
       "      <td>GEO</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15430</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>55 - 60kg</td>\n",
       "      <td>RAHIMOV, Vitaliy</td>\n",
       "      <td>Men</td>\n",
       "      <td>AZE</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15431</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>60 - 66kg</td>\n",
       "      <td>GUENOT, Steeve</td>\n",
       "      <td>Men</td>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Gre-R</td>\n",
       "      <td>96 - 120kg</td>\n",
       "      <td>LOPEZ, Mijain</td>\n",
       "      <td>Men</td>\n",
       "      <td>CUB</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15316 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City    Year      Sport       Discipline           Event  \\\n",
       "0      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "1      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "2      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "3      Montreal  1976.0   Aquatics           Diving  3m springboard   \n",
       "4      Montreal  1976.0   Aquatics           Diving    10m platform   \n",
       "...         ...     ...        ...              ...             ...   \n",
       "15428   Beijing  2008.0  Wrestling  Wrestling Gre-R       66 - 74kg   \n",
       "15429   Beijing  2008.0  Wrestling  Wrestling Gre-R       66 - 74kg   \n",
       "15430   Beijing  2008.0  Wrestling  Wrestling Gre-R       55 - 60kg   \n",
       "15431   Beijing  2008.0  Wrestling  Wrestling Gre-R       60 - 66kg   \n",
       "15432   Beijing  2008.0  Wrestling  Wrestling Gre-R      96 - 120kg   \n",
       "\n",
       "                        Athlete Gender Country_Code        Country  \\\n",
       "0               KÖHLER, Christa  Women          GDR   East Germany   \n",
       "1           KOSENKOV, Aleksandr    Men          URS   Soviet Union   \n",
       "2          BOGGS, Philip George    Men          USA  United States   \n",
       "3      CAGNOTTO, Giorgio Franco    Men          ITA          Italy   \n",
       "4        WILSON, Deborah Keplar  Women          USA  United States   \n",
       "...                         ...    ...          ...            ...   \n",
       "15428        GUENOT, Christophe    Men          FRA         France   \n",
       "15429       KVIRKELIA, Manuchar    Men          GEO        Georgia   \n",
       "15430          RAHIMOV, Vitaliy    Men          AZE     Azerbaijan   \n",
       "15431            GUENOT, Steeve    Men          FRA         France   \n",
       "15432             LOPEZ, Mijain    Men          CUB           Cuba   \n",
       "\n",
       "      Event_gender   Medal  \n",
       "0                W  Silver  \n",
       "1                M  Bronze  \n",
       "2                M    Gold  \n",
       "3                M  Silver  \n",
       "4                W  Bronze  \n",
       "...            ...     ...  \n",
       "15428            M  Bronze  \n",
       "15429            M    Gold  \n",
       "15430            M  Silver  \n",
       "15431            M    Gold  \n",
       "15432            M    Gold  \n",
       "\n",
       "[15316 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how = \"all\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City            15316\n",
       "Year            15316\n",
       "Sport           15316\n",
       "Discipline      15316\n",
       "Event           15316\n",
       "Athlete         15316\n",
       "Gender          15316\n",
       "Country_Code    15316\n",
       "Country         15316\n",
       "Event_gender    15316\n",
       "Medal           15316\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City             object\n",
       "Year            float64\n",
       "Sport            object\n",
       "Discipline       object\n",
       "Event            object\n",
       "Athlete          object\n",
       "Gender           object\n",
       "Country_Code     object\n",
       "Country          object\n",
       "Event_gender     object\n",
       "Medal            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City            object\n",
       "Year             int64\n",
       "Sport           object\n",
       "Discipline      object\n",
       "Event           object\n",
       "Athlete         object\n",
       "Gender          object\n",
       "Country_Code    object\n",
       "Country         object\n",
       "Event_gender    object\n",
       "Medal           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.astype({\"Year\": 'int64'}).dtypes\n",
    "df[\"Year\"] = df[\"Year\"].astype(\"int64\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                9\n",
       "Year                9\n",
       "Sport              28\n",
       "Discipline         41\n",
       "Event             293\n",
       "Athlete         11337\n",
       "Gender              2\n",
       "Country_Code      128\n",
       "Country           127\n",
       "Event_gender        3\n",
       "Medal               3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Country_Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby([\"Country_Code\", \"Medal\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(by=\"Country_Code\")[\"Medal\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country_Code  Medal \n",
       "AFG           Bronze     1\n",
       "AHO           Silver     1\n",
       "ALG           Bronze     8\n",
       "              Gold       4\n",
       "              Silver     2\n",
       "                        ..\n",
       "ZAM           Silver     1\n",
       "              Bronze     1\n",
       "ZIM           Gold      18\n",
       "              Silver     4\n",
       "              Bronze     1\n",
       "Name: count, Length: 302, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=\"Country_Code\")[\"Medal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  Country_Code  Event                       \n",
       "1976  AUS           1500m freestyle                  1\n",
       "                    470 - Two Person Dinghy          2\n",
       "                    hockey                          16\n",
       "                    single-handed dinghy (Finn)      1\n",
       "                    team                             4\n",
       "                                                    ..\n",
       "2008  VIE           - 56kg, total (bantamweight)     1\n",
       "      ZIM           100m backstroke                  1\n",
       "                    200m backstroke                  1\n",
       "                    200m individual medley           1\n",
       "                    400m individual medley           1\n",
       "Name: Medal, Length: 5940, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = df.groupby(by=[\"Year\", \"Country_Code\", \"Event\"])[\"Medal\"].count()\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_Code</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1976</td>\n",
       "      <td>AUS</td>\n",
       "      <td>1500m freestyle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>AUS</td>\n",
       "      <td>470 - Two Person Dinghy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1976</td>\n",
       "      <td>AUS</td>\n",
       "      <td>hockey</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>AUS</td>\n",
       "      <td>single-handed dinghy (Finn)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1976</td>\n",
       "      <td>AUS</td>\n",
       "      <td>team</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>2008</td>\n",
       "      <td>VIE</td>\n",
       "      <td>- 56kg, total (bantamweight)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>2008</td>\n",
       "      <td>ZIM</td>\n",
       "      <td>100m backstroke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>2008</td>\n",
       "      <td>ZIM</td>\n",
       "      <td>200m backstroke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>2008</td>\n",
       "      <td>ZIM</td>\n",
       "      <td>200m individual medley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>2008</td>\n",
       "      <td>ZIM</td>\n",
       "      <td>400m individual medley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5940 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year Country_Code                         Event  Medal\n",
       "0     1976          AUS               1500m freestyle      1\n",
       "1     1976          AUS       470 - Two Person Dinghy      2\n",
       "2     1976          AUS                        hockey     16\n",
       "3     1976          AUS   single-handed dinghy (Finn)      1\n",
       "4     1976          AUS                          team      4\n",
       "...    ...          ...                           ...    ...\n",
       "5935  2008          VIE  - 56kg, total (bantamweight)      1\n",
       "5936  2008          ZIM               100m backstroke      1\n",
       "5937  2008          ZIM               200m backstroke      1\n",
       "5938  2008          ZIM        200m individual medley      1\n",
       "5939  2008          ZIM        400m individual medley      1\n",
       "\n",
       "[5940 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = df_summary.reset_index()\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#abscisa = df_summary[df_summary[\"Country_Code\"] == \"USA\"][\"Year\"].to_list()\n",
    "#abscisa = df_summary[df_summary[\"Country_Code\"] == \"USA\"][\"Year\"]\n",
    "#print(abscisa)\n",
    "#ordenada = df_summary[df_summary[\"Country_Code\"] == \"USA\"][\"Medal\"].to_list()\n",
    "#ordenada = df_summary[df_summary[\"Country_Code\"] == \"USA\"][\"Medal\"]\n",
    "#print(ordenada)\n",
    "\n",
    "plt.plot(df_summary[df_summary[\"Country_Code\"] == \"USA\"][\"Year\"], df_summary[df_summary[\"Country_Code\"] == \"USA\"][\"Medal\"])\n",
    "#df_summary.plot.barh(x=\"Year\", y=\"Medal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Year\"].dtype = \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv(\"./summary.csv\", encoding=\"ISO-8859-1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./medals.csv\", encoding=\"ISO-8859-1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRUD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "#y = result_query7[[\"country\", \"medal\"]]\n",
    "\n",
    "# Separate the X variable, the features\n",
    "#X = result_query7[[\"city\", \"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDAS\n",
    "# Separate the data into labels and features\n",
    "X = df_summary[[\"Year\", \"Country_Code\", \"Event\"]]\n",
    "\n",
    "# Separate the X variable, the features\n",
    "#y = df_summary[[\"Medal\"]]\n",
    "y = df_summary[\"Medal\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2 16 ...  1  1  1]\n",
      "      Year Country_Code                         Event\n",
      "0     1976          AUS               1500m freestyle\n",
      "1     1976          AUS       470 - Two Person Dinghy\n",
      "2     1976          AUS                        hockey\n",
      "3     1976          AUS   single-handed dinghy (Finn)\n",
      "4     1976          AUS                          team\n",
      "...    ...          ...                           ...\n",
      "5935  2008          VIE  - 56kg, total (bantamweight)\n",
      "5936  2008          ZIM               100m backstroke\n",
      "5937  2008          ZIM               200m backstroke\n",
      "5938  2008          ZIM        200m individual medley\n",
      "5939  2008          ZIM        400m individual medley\n",
      "\n",
      "[5940 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Encode categorical to numerical values \n",
    "# cc_encoded = pd.get_dummies(X[\"Country_Code\"]).astype(\"int\")\n",
    "# cc_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country_Code_AFG</th>\n",
       "      <th>Country_Code_AHO</th>\n",
       "      <th>Country_Code_ALG</th>\n",
       "      <th>Country_Code_ARG</th>\n",
       "      <th>Country_Code_ARM</th>\n",
       "      <th>Country_Code_AUS</th>\n",
       "      <th>Country_Code_AUT</th>\n",
       "      <th>Country_Code_AZE</th>\n",
       "      <th>Country_Code_BAH</th>\n",
       "      <th>...</th>\n",
       "      <th>Event_trap (125 targets)</th>\n",
       "      <th>Event_trap (75 targets)</th>\n",
       "      <th>Event_triple jump</th>\n",
       "      <th>Event_two-person keelboat open (Star)</th>\n",
       "      <th>Event_uneven bars</th>\n",
       "      <th>Event_vault</th>\n",
       "      <th>Event_volleyball</th>\n",
       "      <th>Event_water polo</th>\n",
       "      <th>Event_épée individual</th>\n",
       "      <th>Event_épée team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5940 rows × 422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Country_Code_AFG  Country_Code_AHO  Country_Code_ALG  \\\n",
       "0     1976                 0                 0                 0   \n",
       "1     1976                 0                 0                 0   \n",
       "2     1976                 0                 0                 0   \n",
       "3     1976                 0                 0                 0   \n",
       "4     1976                 0                 0                 0   \n",
       "...    ...               ...               ...               ...   \n",
       "5935  2008                 0                 0                 0   \n",
       "5936  2008                 0                 0                 0   \n",
       "5937  2008                 0                 0                 0   \n",
       "5938  2008                 0                 0                 0   \n",
       "5939  2008                 0                 0                 0   \n",
       "\n",
       "      Country_Code_ARG  Country_Code_ARM  Country_Code_AUS  Country_Code_AUT  \\\n",
       "0                    0                 0                 1                 0   \n",
       "1                    0                 0                 1                 0   \n",
       "2                    0                 0                 1                 0   \n",
       "3                    0                 0                 1                 0   \n",
       "4                    0                 0                 1                 0   \n",
       "...                ...               ...               ...               ...   \n",
       "5935                 0                 0                 0                 0   \n",
       "5936                 0                 0                 0                 0   \n",
       "5937                 0                 0                 0                 0   \n",
       "5938                 0                 0                 0                 0   \n",
       "5939                 0                 0                 0                 0   \n",
       "\n",
       "      Country_Code_AZE  Country_Code_BAH  ...  Event_trap (125 targets)  \\\n",
       "0                    0                 0  ...                         0   \n",
       "1                    0                 0  ...                         0   \n",
       "2                    0                 0  ...                         0   \n",
       "3                    0                 0  ...                         0   \n",
       "4                    0                 0  ...                         0   \n",
       "...                ...               ...  ...                       ...   \n",
       "5935                 0                 0  ...                         0   \n",
       "5936                 0                 0  ...                         0   \n",
       "5937                 0                 0  ...                         0   \n",
       "5938                 0                 0  ...                         0   \n",
       "5939                 0                 0  ...                         0   \n",
       "\n",
       "      Event_trap (75 targets)  Event_triple jump  \\\n",
       "0                           0                  0   \n",
       "1                           0                  0   \n",
       "2                           0                  0   \n",
       "3                           0                  0   \n",
       "4                           0                  0   \n",
       "...                       ...                ...   \n",
       "5935                        0                  0   \n",
       "5936                        0                  0   \n",
       "5937                        0                  0   \n",
       "5938                        0                  0   \n",
       "5939                        0                  0   \n",
       "\n",
       "      Event_two-person keelboat open (Star)  Event_uneven bars  Event_vault  \\\n",
       "0                                         0                  0            0   \n",
       "1                                         0                  0            0   \n",
       "2                                         0                  0            0   \n",
       "3                                         0                  0            0   \n",
       "4                                         0                  0            0   \n",
       "...                                     ...                ...          ...   \n",
       "5935                                      0                  0            0   \n",
       "5936                                      0                  0            0   \n",
       "5937                                      0                  0            0   \n",
       "5938                                      0                  0            0   \n",
       "5939                                      0                  0            0   \n",
       "\n",
       "      Event_volleyball  Event_water polo  Event_épée individual  \\\n",
       "0                    0                 0                      0   \n",
       "1                    0                 0                      0   \n",
       "2                    0                 0                      0   \n",
       "3                    0                 0                      0   \n",
       "4                    0                 0                      0   \n",
       "...                ...               ...                    ...   \n",
       "5935                 0                 0                      0   \n",
       "5936                 0                 0                      0   \n",
       "5937                 0                 0                      0   \n",
       "5938                 0                 0                      0   \n",
       "5939                 0                 0                      0   \n",
       "\n",
       "      Event_épée team  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "5935                0  \n",
       "5936                0  \n",
       "5937                0  \n",
       "5938                0  \n",
       "5939                0  \n",
       "\n",
       "[5940 rows x 422 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode categorical to numerical values \n",
    "summary_encoded = pd.get_dummies(X).astype(\"int\")\n",
    "summary_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_encoded.to_csv(\"summary_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.assign(uno = 1).pivot_table(index = \"country\", columns=\"medal\", aggfunc={\"uno\" : \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = summary_encoded\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.97303550e-01, -1.49839010e-02, -1.49839010e-02, -4.24142145e-02,\n",
       "       -6.54456871e-02, -4.49921271e-02, -2.03407163e-01, -6.71534278e-02,\n",
       "       -5.40981482e-02, -3.35200762e-02, -1.49839010e-02,  0.00000000e+00,\n",
       "       -7.51221729e-02,  0.00000000e+00, -9.63775238e-02, -1.06539841e-01,\n",
       "       -1.57622081e-01, -1.51532546e-01, -2.59587066e-02, -2.20186275e-01,\n",
       "       -1.49839010e-02, -2.11928152e-02, -3.96704047e-02, -2.11928152e-02,\n",
       "       -5.81238194e-02, -1.67797533e-01, -7.51221729e-02, -8.09456089e-02,\n",
       "       -1.49839010e-02, -2.59587066e-02, -2.11928152e-02, -2.99778994e-02,\n",
       "       -1.49839010e-02, -1.32619530e-01, -3.67235302e-02, -4.97518595e-02,\n",
       "       -1.18799672e-01, -8.37092186e-02, -1.95498157e-01, -1.33493164e-01,\n",
       "       -1.89223747e-01, -2.00396525e-01, -5.61466218e-02, -2.04004795e-01,\n",
       "       -1.49839010e-02, -9.39761764e-02, -1.49839010e-02, -2.11928152e-02,\n",
       "       -1.62781129e-01, -5.81238194e-02, -3.67235302e-02, -2.11928152e-02,\n",
       "       -6.71534278e-02, -4.97518595e-02, -2.59587066e-02, -3.35200762e-02,\n",
       "        0.00000000e+00, -1.89223747e-01, -7.80868809e-02, -1.76776695e-01,\n",
       "       -8.09456089e-02, -7.80868809e-02, -2.11928152e-02, -1.65664267e-01,\n",
       "       -1.49839010e-02, -1.49839010e-02, -4.97518595e-02, -1.49839010e-02,\n",
       "       -4.74312005e-02, -5.40981482e-02, -2.59587066e-02, -2.99778994e-02,\n",
       "       -6.54456871e-02, -4.24142145e-02, -1.49839010e-02, -1.49839010e-02,\n",
       "       -1.49839010e-02, -2.99778994e-02, -1.42775318e-01, -5.40981482e-02,\n",
       "       -8.50582649e-02, -9.39761764e-02, -2.11928152e-02, -1.49839010e-02,\n",
       "        0.00000000e+00, -2.59587066e-02, -1.49839010e-02, -1.58368349e-01,\n",
       "       -5.19699700e-02, -7.66185333e-02, -2.59587066e-02, -2.11928152e-02,\n",
       "       -1.82107840e-01, -5.61466218e-02, -2.16802964e-01, -2.11928152e-02,\n",
       "       -1.49839010e-02, -1.49839010e-02, -5.61466218e-02, -2.11928152e-02,\n",
       "       -1.49839010e-02, -1.49839010e-02, -8.23386970e-02, -1.49839010e-02,\n",
       "       -5.61466218e-02, -1.23567452e-01, -2.59587066e-02, -2.11928152e-02,\n",
       "       -8.23386970e-02, -1.49839010e-02, -5.40981482e-02, -1.49839010e-02,\n",
       "       -1.49839010e-02, -5.40981482e-02, -3.67235302e-02, -2.11928152e-02,\n",
       "       -7.95287680e-02, -1.49839010e-02, -2.11928152e-02, -1.23567452e-01,\n",
       "       -2.38094109e-01, -1.49839010e-02,  3.09547214e+00, -4.74312005e-02,\n",
       "       -2.99778994e-02, -1.49839010e-02, -9.51841513e-02, -1.49839010e-02,\n",
       "       -3.67235302e-02, -5.61466218e-02, -4.74312005e-02, -3.96704047e-02,\n",
       "       -2.59587066e-02, -4.49921271e-02, -4.74312005e-02, -3.96704047e-02,\n",
       "       -3.67235302e-02, -3.96704047e-02, -3.96704047e-02, -2.59587066e-02,\n",
       "       -6.71534278e-02, -2.99778994e-02, -5.19699700e-02, -3.35200762e-02,\n",
       "       -2.59587066e-02, -4.74312005e-02, -8.89862463e-02, -3.67235302e-02,\n",
       "       -3.67235302e-02, -2.11928152e-02, -4.49921271e-02, -5.19699700e-02,\n",
       "       -4.24142145e-02, -6.71534278e-02, -2.11928152e-02, -4.97518595e-02,\n",
       "       -4.49921271e-02, -7.95287680e-02, -2.99778994e-02, -8.37092186e-02,\n",
       "       -8.09456089e-02, -8.23386970e-02, -7.80868809e-02, -8.23386970e-02,\n",
       "       -6.36929755e-02, -3.35200762e-02, -5.40981482e-02, -5.19699700e-02,\n",
       "       -5.61466218e-02, -5.81238194e-02, -7.20383973e-02, -2.99778994e-02,\n",
       "       -5.19699700e-02, -8.09456089e-02, -6.36929755e-02, -7.04469954e-02,\n",
       "       -7.66185333e-02, -8.50582649e-02, -8.09456089e-02, -8.23386970e-02,\n",
       "       -7.95287680e-02, -7.20383973e-02, -3.96704047e-02, -7.04469954e-02,\n",
       "       -5.81238194e-02, -6.71534278e-02, -4.24142145e-02, -6.00367838e-02,\n",
       "       -7.51221729e-02, -7.20383973e-02, -7.80868809e-02, -7.80868809e-02,\n",
       "       -8.76958821e-02, -7.95287680e-02, -7.04469954e-02, -7.20383973e-02,\n",
       "       -6.18914720e-02, -2.99778994e-02, -3.67235302e-02, -3.35200762e-02,\n",
       "       -3.96704047e-02, -4.74312005e-02, -3.96704047e-02, -7.51221729e-02,\n",
       "       -8.09456089e-02, -7.80868809e-02, -6.36929755e-02, -8.37092186e-02,\n",
       "       -7.04469954e-02, -3.35200762e-02, -5.81238194e-02, -7.04469954e-02,\n",
       "       -6.54456871e-02, -6.18914720e-02, -6.18914720e-02, -6.36929755e-02,\n",
       "       -5.19699700e-02, -6.54456871e-02, -3.67235302e-02, -7.35960907e-02,\n",
       "       -4.97518595e-02, -3.96704047e-02, -7.95287680e-02, -3.35200762e-02,\n",
       "       -2.59587066e-02, -4.49921271e-02, -2.99778994e-02, -5.61466218e-02,\n",
       "       -2.99778994e-02, -2.11928152e-02, -7.51221729e-02, -7.51221729e-02,\n",
       "       -5.19699700e-02, -4.49921271e-02, -2.59587066e-02, -4.49921271e-02,\n",
       "       -3.96704047e-02, -2.59587066e-02, -6.71534278e-02, -3.35200762e-02,\n",
       "       -5.61466218e-02, -4.97518595e-02, -5.81238194e-02, -5.19699700e-02,\n",
       "       -3.96704047e-02, -6.88195460e-02, -3.67235302e-02, -2.99778994e-02,\n",
       "       -2.11928152e-02, -3.67235302e-02, -3.67235302e-02, -6.18914720e-02,\n",
       "       -4.24142145e-02, -3.96704047e-02, -2.11928152e-02, -5.61466218e-02,\n",
       "       -3.35200762e-02, -5.61466218e-02, -3.96704047e-02, -6.36929755e-02,\n",
       "       -4.74312005e-02, -7.66185333e-02, -4.24142145e-02, -3.67235302e-02,\n",
       "       -2.99778994e-02, -5.19699700e-02, -2.59587066e-02, -4.49921271e-02,\n",
       "       -2.59587066e-02, -5.81238194e-02, -7.35960907e-02, -5.61466218e-02,\n",
       "       -7.66185333e-02, -4.24142145e-02, -8.37092186e-02, -5.19699700e-02,\n",
       "       -2.99778994e-02, -2.11928152e-02, -2.59587066e-02, -3.96704047e-02,\n",
       "       -4.74312005e-02, -2.59587066e-02, -7.95287680e-02, -6.36929755e-02,\n",
       "       -5.19699700e-02, -7.04469954e-02, -6.54456871e-02, -3.96704047e-02,\n",
       "       -2.11928152e-02, -5.19699700e-02, -2.99778994e-02, -3.67235302e-02,\n",
       "       -5.40981482e-02, -4.97518595e-02, -7.35960907e-02, -4.24142145e-02,\n",
       "       -2.59587066e-02, -2.59587066e-02, -3.96704047e-02, -4.49921271e-02,\n",
       "       -2.11928152e-02, -2.59587066e-02, -4.74312005e-02, -6.54456871e-02,\n",
       "       -7.04469954e-02, -4.74312005e-02, -7.04469954e-02, -6.88195460e-02,\n",
       "       -2.11928152e-02, -5.40981482e-02, -5.81238194e-02, -7.35960907e-02,\n",
       "       -6.71534278e-02, -7.04469954e-02, -8.89862463e-02, -6.36929755e-02,\n",
       "       -8.89862463e-02, -6.36929755e-02, -6.18914720e-02, -2.59587066e-02,\n",
       "       -2.11928152e-02, -2.59587066e-02, -3.96704047e-02, -2.59587066e-02,\n",
       "       -5.81238194e-02, -3.67235302e-02, -6.88195460e-02, -2.99778994e-02,\n",
       "       -6.54456871e-02, -3.67235302e-02, -5.40981482e-02, -7.20383973e-02,\n",
       "       -3.35200762e-02, -6.18914720e-02, -5.40981482e-02, -8.09456089e-02,\n",
       "       -4.49921271e-02, -5.81238194e-02, -2.11928152e-02, -2.99778994e-02,\n",
       "       -2.11928152e-02, -2.59587066e-02, -7.04469954e-02, -6.00367838e-02,\n",
       "       -6.36929755e-02, -7.95287680e-02, -9.15140986e-02, -2.99778994e-02,\n",
       "       -4.74312005e-02, -9.87225753e-02, -5.61466218e-02, -8.23386970e-02,\n",
       "       -4.74312005e-02, -8.76958821e-02, -5.61466218e-02, -8.09456089e-02,\n",
       "       -8.50582649e-02, -7.51221729e-02, -6.36929755e-02, -6.36929755e-02,\n",
       "       -4.74312005e-02, -6.18914720e-02, -8.89862463e-02, -5.40981482e-02,\n",
       "       -9.39761764e-02, -7.95287680e-02, -7.35960907e-02, -9.02587365e-02,\n",
       "       -6.36929755e-02, -4.49921271e-02, -8.50582649e-02, -5.19699700e-02,\n",
       "       -7.80868809e-02, -5.40981482e-02, -8.50582649e-02, -3.96704047e-02,\n",
       "       -5.40981482e-02, -8.09456089e-02, -8.23386970e-02, -2.59587066e-02,\n",
       "       -5.19699700e-02, -7.04469954e-02, -5.40981482e-02, -6.36929755e-02,\n",
       "       -2.11928152e-02, -4.97518595e-02, -7.04469954e-02, -7.20383973e-02,\n",
       "       -4.24142145e-02, -8.23386970e-02, -6.00367838e-02, -6.54456871e-02,\n",
       "       -6.71534278e-02, -8.09456089e-02, -8.63868426e-02, -4.49921271e-02,\n",
       "       -6.71534278e-02, -3.67235302e-02, -1.01015254e-01, -6.71534278e-02,\n",
       "       -3.35200762e-02, -3.67235302e-02, -3.67235302e-02, -6.00367838e-02,\n",
       "       -4.74312005e-02, -4.74312005e-02, -1.08674420e-01, -6.18914720e-02,\n",
       "       -8.09456089e-02,  1.84849211e+01, -2.59587066e-02, -1.49839010e-02,\n",
       "       -7.04469954e-02, -3.67235302e-02, -6.88195460e-02, -5.61466218e-02,\n",
       "       -5.81238194e-02, -8.37092186e-02, -8.23386970e-02, -7.80868809e-02,\n",
       "       -7.51221729e-02, -6.71534278e-02])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.39891433e+00, -1.49839010e-02, -1.49839010e-02, -4.24142145e-02,\n",
       "       -6.54456871e-02, -4.49921271e-02, -2.03407163e-01, -6.71534278e-02,\n",
       "       -5.40981482e-02, -3.35200762e-02, -1.49839010e-02,  0.00000000e+00,\n",
       "       -7.51221729e-02,  0.00000000e+00, -9.63775238e-02, -1.06539841e-01,\n",
       "       -1.57622081e-01, -1.51532546e-01, -2.59587066e-02, -2.20186275e-01,\n",
       "       -1.49839010e-02, -2.11928152e-02, -3.96704047e-02, -2.11928152e-02,\n",
       "       -5.81238194e-02, -1.67797533e-01, -7.51221729e-02, -8.09456089e-02,\n",
       "       -1.49839010e-02, -2.59587066e-02, -2.11928152e-02, -2.99778994e-02,\n",
       "       -1.49839010e-02, -1.32619530e-01, -3.67235302e-02, -4.97518595e-02,\n",
       "       -1.18799672e-01, -8.37092186e-02, -1.95498157e-01, -1.33493164e-01,\n",
       "       -1.89223747e-01, -2.00396525e-01, -5.61466218e-02, -2.04004795e-01,\n",
       "       -1.49839010e-02, -9.39761764e-02, -1.49839010e-02, -2.11928152e-02,\n",
       "       -1.62781129e-01, -5.81238194e-02, -3.67235302e-02, -2.11928152e-02,\n",
       "       -6.71534278e-02, -4.97518595e-02, -2.59587066e-02, -3.35200762e-02,\n",
       "        0.00000000e+00, -1.89223747e-01, -7.80868809e-02, -1.76776695e-01,\n",
       "       -8.09456089e-02, -7.80868809e-02, -2.11928152e-02, -1.65664267e-01,\n",
       "       -1.49839010e-02, -1.49839010e-02, -4.97518595e-02, -1.49839010e-02,\n",
       "       -4.74312005e-02, -5.40981482e-02, -2.59587066e-02, -2.99778994e-02,\n",
       "       -6.54456871e-02, -4.24142145e-02, -1.49839010e-02, -1.49839010e-02,\n",
       "       -1.49839010e-02, -2.99778994e-02, -1.42775318e-01, -5.40981482e-02,\n",
       "       -8.50582649e-02, -9.39761764e-02, -2.11928152e-02, -1.49839010e-02,\n",
       "        0.00000000e+00, -2.59587066e-02, -1.49839010e-02, -1.58368349e-01,\n",
       "       -5.19699700e-02, -7.66185333e-02, -2.59587066e-02, -2.11928152e-02,\n",
       "       -1.82107840e-01, -5.61466218e-02, -2.16802964e-01, -2.11928152e-02,\n",
       "       -1.49839010e-02, -1.49839010e-02, -5.61466218e-02,  4.71858029e+01,\n",
       "       -1.49839010e-02, -1.49839010e-02, -8.23386970e-02, -1.49839010e-02,\n",
       "       -5.61466218e-02, -1.23567452e-01, -2.59587066e-02, -2.11928152e-02,\n",
       "       -8.23386970e-02, -1.49839010e-02, -5.40981482e-02, -1.49839010e-02,\n",
       "       -1.49839010e-02, -5.40981482e-02, -3.67235302e-02, -2.11928152e-02,\n",
       "       -7.95287680e-02, -1.49839010e-02, -2.11928152e-02, -1.23567452e-01,\n",
       "       -2.38094109e-01, -1.49839010e-02, -3.23052496e-01, -4.74312005e-02,\n",
       "       -2.99778994e-02, -1.49839010e-02, -9.51841513e-02, -1.49839010e-02,\n",
       "       -3.67235302e-02, -5.61466218e-02, -4.74312005e-02, -3.96704047e-02,\n",
       "       -2.59587066e-02, -4.49921271e-02, -4.74312005e-02, -3.96704047e-02,\n",
       "       -3.67235302e-02, -3.96704047e-02, -3.96704047e-02, -2.59587066e-02,\n",
       "       -6.71534278e-02, -2.99778994e-02, -5.19699700e-02, -3.35200762e-02,\n",
       "       -2.59587066e-02, -4.74312005e-02, -8.89862463e-02, -3.67235302e-02,\n",
       "       -3.67235302e-02, -2.11928152e-02, -4.49921271e-02, -5.19699700e-02,\n",
       "       -4.24142145e-02, -6.71534278e-02, -2.11928152e-02, -4.97518595e-02,\n",
       "       -4.49921271e-02, -7.95287680e-02, -2.99778994e-02, -8.37092186e-02,\n",
       "       -8.09456089e-02, -8.23386970e-02, -7.80868809e-02, -8.23386970e-02,\n",
       "       -6.36929755e-02, -3.35200762e-02, -5.40981482e-02, -5.19699700e-02,\n",
       "       -5.61466218e-02, -5.81238194e-02, -7.20383973e-02, -2.99778994e-02,\n",
       "       -5.19699700e-02, -8.09456089e-02, -6.36929755e-02, -7.04469954e-02,\n",
       "       -7.66185333e-02, -8.50582649e-02, -8.09456089e-02, -8.23386970e-02,\n",
       "       -7.95287680e-02, -7.20383973e-02, -3.96704047e-02, -7.04469954e-02,\n",
       "       -5.81238194e-02, -6.71534278e-02, -4.24142145e-02, -6.00367838e-02,\n",
       "       -7.51221729e-02, -7.20383973e-02, -7.80868809e-02, -7.80868809e-02,\n",
       "       -8.76958821e-02, -7.95287680e-02, -7.04469954e-02, -7.20383973e-02,\n",
       "       -6.18914720e-02, -2.99778994e-02, -3.67235302e-02, -3.35200762e-02,\n",
       "       -3.96704047e-02, -4.74312005e-02, -3.96704047e-02, -7.51221729e-02,\n",
       "       -8.09456089e-02, -7.80868809e-02, -6.36929755e-02, -8.37092186e-02,\n",
       "       -7.04469954e-02, -3.35200762e-02, -5.81238194e-02, -7.04469954e-02,\n",
       "       -6.54456871e-02, -6.18914720e-02, -6.18914720e-02, -6.36929755e-02,\n",
       "       -5.19699700e-02, -6.54456871e-02, -3.67235302e-02, -7.35960907e-02,\n",
       "       -4.97518595e-02, -3.96704047e-02, -7.95287680e-02, -3.35200762e-02,\n",
       "       -2.59587066e-02, -4.49921271e-02, -2.99778994e-02, -5.61466218e-02,\n",
       "       -2.99778994e-02, -2.11928152e-02, -7.51221729e-02, -7.51221729e-02,\n",
       "       -5.19699700e-02, -4.49921271e-02, -2.59587066e-02, -4.49921271e-02,\n",
       "       -3.96704047e-02, -2.59587066e-02, -6.71534278e-02, -3.35200762e-02,\n",
       "       -5.61466218e-02, -4.97518595e-02, -5.81238194e-02, -5.19699700e-02,\n",
       "       -3.96704047e-02, -6.88195460e-02, -3.67235302e-02, -2.99778994e-02,\n",
       "       -2.11928152e-02, -3.67235302e-02, -3.67235302e-02, -6.18914720e-02,\n",
       "       -4.24142145e-02, -3.96704047e-02, -2.11928152e-02, -5.61466218e-02,\n",
       "       -3.35200762e-02, -5.61466218e-02, -3.96704047e-02, -6.36929755e-02,\n",
       "       -4.74312005e-02, -7.66185333e-02, -4.24142145e-02, -3.67235302e-02,\n",
       "       -2.99778994e-02, -5.19699700e-02, -2.59587066e-02, -4.49921271e-02,\n",
       "       -2.59587066e-02, -5.81238194e-02, -7.35960907e-02, -5.61466218e-02,\n",
       "       -7.66185333e-02, -4.24142145e-02, -8.37092186e-02, -5.19699700e-02,\n",
       "       -2.99778994e-02, -2.11928152e-02, -2.59587066e-02, -3.96704047e-02,\n",
       "       -4.74312005e-02, -2.59587066e-02, -7.95287680e-02, -6.36929755e-02,\n",
       "       -5.19699700e-02, -7.04469954e-02, -6.54456871e-02, -3.96704047e-02,\n",
       "       -2.11928152e-02, -5.19699700e-02, -2.99778994e-02, -3.67235302e-02,\n",
       "       -5.40981482e-02, -4.97518595e-02, -7.35960907e-02, -4.24142145e-02,\n",
       "       -2.59587066e-02, -2.59587066e-02, -3.96704047e-02, -4.49921271e-02,\n",
       "       -2.11928152e-02, -2.59587066e-02, -4.74312005e-02, -6.54456871e-02,\n",
       "       -7.04469954e-02, -4.74312005e-02, -7.04469954e-02, -6.88195460e-02,\n",
       "       -2.11928152e-02, -5.40981482e-02, -5.81238194e-02, -7.35960907e-02,\n",
       "       -6.71534278e-02, -7.04469954e-02, -8.89862463e-02, -6.36929755e-02,\n",
       "       -8.89862463e-02, -6.36929755e-02, -6.18914720e-02, -2.59587066e-02,\n",
       "       -2.11928152e-02, -2.59587066e-02, -3.96704047e-02, -2.59587066e-02,\n",
       "       -5.81238194e-02, -3.67235302e-02, -6.88195460e-02, -2.99778994e-02,\n",
       "       -6.54456871e-02, -3.67235302e-02, -5.40981482e-02, -7.20383973e-02,\n",
       "       -3.35200762e-02, -6.18914720e-02, -5.40981482e-02, -8.09456089e-02,\n",
       "       -4.49921271e-02, -5.81238194e-02, -2.11928152e-02, -2.99778994e-02,\n",
       "       -2.11928152e-02, -2.59587066e-02, -7.04469954e-02, -6.00367838e-02,\n",
       "       -6.36929755e-02, -7.95287680e-02, -9.15140986e-02, -2.99778994e-02,\n",
       "       -4.74312005e-02, -9.87225753e-02, -5.61466218e-02, -8.23386970e-02,\n",
       "       -4.74312005e-02, -8.76958821e-02, -5.61466218e-02, -8.09456089e-02,\n",
       "       -8.50582649e-02, -7.51221729e-02, -6.36929755e-02, -6.36929755e-02,\n",
       "       -4.74312005e-02, -6.18914720e-02, -8.89862463e-02, -5.40981482e-02,\n",
       "       -9.39761764e-02, -7.95287680e-02, -7.35960907e-02, -9.02587365e-02,\n",
       "       -6.36929755e-02, -4.49921271e-02, -8.50582649e-02, -5.19699700e-02,\n",
       "       -7.80868809e-02, -5.40981482e-02, -8.50582649e-02, -3.96704047e-02,\n",
       "       -5.40981482e-02, -8.09456089e-02, -8.23386970e-02, -2.59587066e-02,\n",
       "       -5.19699700e-02, -7.04469954e-02, -5.40981482e-02, -6.36929755e-02,\n",
       "       -2.11928152e-02, -4.97518595e-02, -7.04469954e-02, -7.20383973e-02,\n",
       "       -4.24142145e-02, -8.23386970e-02, -6.00367838e-02, -6.54456871e-02,\n",
       "       -6.71534278e-02, -8.09456089e-02, -8.63868426e-02, -4.49921271e-02,\n",
       "       -6.71534278e-02, -3.67235302e-02, -1.01015254e-01, -6.71534278e-02,\n",
       "       -3.35200762e-02, -3.67235302e-02, -3.67235302e-02, -6.00367838e-02,\n",
       "       -4.74312005e-02, -4.74312005e-02, -1.08674420e-01, -6.18914720e-02,\n",
       "       -8.09456089e-02, -5.40981482e-02, -2.59587066e-02, -1.49839010e-02,\n",
       "       -7.04469954e-02, -3.67235302e-02, -6.88195460e-02, -5.61466218e-02,\n",
       "       -5.81238194e-02, -8.37092186e-02, -8.23386970e-02,  1.28062485e+01,\n",
       "       -7.51221729e-02, -6.71534278e-02])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model\n",
    "\n",
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000, random_state=1))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', random_state=1, max_iter=1000))   # default max_iter=100\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "lrm = LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000)   # default max_iter=100\n",
    "\n",
    "# Fit the model using training data\n",
    "lrm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "y_lrm_pred = lrm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46164172268077114"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_lrm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[882,  23,   6,   3,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [104, 116,   1,   5,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 24,   4,  23,   6,   2,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  6,   9,   2,  74,   5,   3,   0,   4,   3,   3,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,  11,  10,   1,   0,   0,   0,   2,   0,   0,   0,\n",
       "          1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   6,   0,  12,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   6,   0,   2,   0,   3,   1,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,  10,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   3,   0,   1,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   5,   0,   2,   0,   0,   0,   0,   0,  20,   0,\n",
       "          0,   0,   0,   1,   0,   0,   5,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   2,\n",
       "          1,   3,   1,   0,   1,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   7,   1,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   1,\n",
       "          0,   1,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1,   3,   2,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,\n",
       "          0,   0,   1,   1,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   1,   5,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_matrix(y_test, y_lrm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n",
      "Mean Squared Error: 1.5239057239057239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are prepared from historical data\n",
    "\n",
    "# Instantiate the model\n",
    "rf_model = RandomForestRegressor(random_state=42)   # default n_estimators=100 \n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_rf_pred = rf_model.predict(X_test_scaled).astype(\"int\")\n",
    "print(len(y_rf_pred))\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_rf_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  1  1 ...  2  4  1]\n",
      "[13  1  1 ...  1  4  1]\n"
     ]
    }
   ],
   "source": [
    "#y_test_array = y_test[\"Medal\"].to_list()\n",
    "print(y_test)\n",
    "print(y_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "           Predicted 1  Predicted 2  Predicted 3  Predicted 4  Predicted 5  \\\n",
      "Actual 1           903           11            1            0            0   \n",
      "Actual 2           117          104            6            0            0   \n",
      "Actual 3            19           15           22            2            4   \n",
      "Actual 4             3           13           14           59            8   \n",
      "Actual 5             0            0            0            7           13   \n",
      "Actual 6             0            0            0            3            5   \n",
      "Actual 7             0            0            0            0            0   \n",
      "Actual 8             0            0            1            5            1   \n",
      "Actual 9             0            0            0            0            1   \n",
      "Actual 10            0            0            0            0            1   \n",
      "Actual 11            0            0            0            0            0   \n",
      "Actual 12            0            0            0            0            2   \n",
      "Actual 13            0            0            0            0            0   \n",
      "Actual 14            0            0            0            0            0   \n",
      "Actual 15            0            0            0            0            0   \n",
      "Actual 16            0            0            0            0            0   \n",
      "Actual 17            0            0            0            0            0   \n",
      "Actual 18            0            0            0            0            0   \n",
      "Actual 19            0            0            0            0            0   \n",
      "Actual 20            0            0            0            0            0   \n",
      "Actual 21            0            0            0            0            0   \n",
      "Actual 22            0            0            0            0            0   \n",
      "Actual 23            0            0            0            0            0   \n",
      "Actual 24            0            0            0            0            0   \n",
      "Actual 25            0            0            0            0            0   \n",
      "Actual 26            0            0            0            0            0   \n",
      "Actual 32            0            0            0            0            0   \n",
      "Actual 36            0            0            0            0            0   \n",
      "\n",
      "           Predicted 6  Predicted 7  Predicted 8  Predicted 9  Predicted 10  \\\n",
      "Actual 1             0            0            0            0             0   \n",
      "Actual 2             0            0            0            0             0   \n",
      "Actual 3             0            0            0            0             0   \n",
      "Actual 4             5            5            1            0             1   \n",
      "Actual 5             2            0            0            2             1   \n",
      "Actual 6             6            1            1            0             2   \n",
      "Actual 7             0            1            1            0             0   \n",
      "Actual 8             0            3            1            1             0   \n",
      "Actual 9             0            0            0            6             2   \n",
      "Actual 10            3            1            0            0             0   \n",
      "Actual 11            0            0            0            0             1   \n",
      "Actual 12            0            4            1            0             1   \n",
      "Actual 13            0            0            0            0             0   \n",
      "Actual 14            0            0            0            0             0   \n",
      "Actual 15            0            0            0            0             0   \n",
      "Actual 16            0            0            0            0             0   \n",
      "Actual 17            0            0            0            0             0   \n",
      "Actual 18            0            0            0            1             0   \n",
      "Actual 19            0            0            0            0             0   \n",
      "Actual 20            0            0            0            0             0   \n",
      "Actual 21            0            0            0            0             0   \n",
      "Actual 22            0            0            0            0             0   \n",
      "Actual 23            0            0            0            0             0   \n",
      "Actual 24            0            0            0            0             0   \n",
      "Actual 25            0            0            0            0             0   \n",
      "Actual 26            0            0            0            0             0   \n",
      "Actual 32            0            0            0            0             0   \n",
      "Actual 36            0            0            0            0             0   \n",
      "\n",
      "           ...  Predicted 19  Predicted 20  Predicted 21  Predicted 22  \\\n",
      "Actual 1   ...             0             0             0             0   \n",
      "Actual 2   ...             0             0             0             0   \n",
      "Actual 3   ...             0             0             0             0   \n",
      "Actual 4   ...             0             0             0             0   \n",
      "Actual 5   ...             0             0             0             0   \n",
      "Actual 6   ...             0             0             0             0   \n",
      "Actual 7   ...             0             0             0             0   \n",
      "Actual 8   ...             0             0             0             0   \n",
      "Actual 9   ...             0             0             0             0   \n",
      "Actual 10  ...             0             0             0             0   \n",
      "Actual 11  ...             0             0             0             0   \n",
      "Actual 12  ...             1             0             0             0   \n",
      "Actual 13  ...             0             0             0             0   \n",
      "Actual 14  ...             0             0             0             1   \n",
      "Actual 15  ...             0             0             0             0   \n",
      "Actual 16  ...             0             1             0             0   \n",
      "Actual 17  ...             1             0             0             0   \n",
      "Actual 18  ...             0             0             0             0   \n",
      "Actual 19  ...             0             0             0             0   \n",
      "Actual 20  ...             0             0             0             0   \n",
      "Actual 21  ...             0             0             0             0   \n",
      "Actual 22  ...             0             0             0             0   \n",
      "Actual 23  ...             0             0             0             0   \n",
      "Actual 24  ...             0             0             1             0   \n",
      "Actual 25  ...             0             0             0             0   \n",
      "Actual 26  ...             0             0             0             0   \n",
      "Actual 32  ...             0             0             0             0   \n",
      "Actual 36  ...             0             0             0             0   \n",
      "\n",
      "           Predicted 23  Predicted 24  Predicted 25  Predicted 26  \\\n",
      "Actual 1              0             0             0             0   \n",
      "Actual 2              0             0             0             0   \n",
      "Actual 3              0             0             0             0   \n",
      "Actual 4              0             0             0             0   \n",
      "Actual 5              0             0             0             0   \n",
      "Actual 6              0             0             0             0   \n",
      "Actual 7              0             0             0             0   \n",
      "Actual 8              0             0             0             0   \n",
      "Actual 9              0             0             0             0   \n",
      "Actual 10             0             0             0             0   \n",
      "Actual 11             0             0             0             0   \n",
      "Actual 12             0             0             0             0   \n",
      "Actual 13             0             0             0             0   \n",
      "Actual 14             0             0             0             0   \n",
      "Actual 15             0             1             0             0   \n",
      "Actual 16             0             0             0             0   \n",
      "Actual 17             0             0             0             1   \n",
      "Actual 18             0             0             0             0   \n",
      "Actual 19             0             0             0             0   \n",
      "Actual 20             0             0             0             0   \n",
      "Actual 21             0             0             0             0   \n",
      "Actual 22             0             0             0             0   \n",
      "Actual 23             0             0             0             0   \n",
      "Actual 24             5             0             0             0   \n",
      "Actual 25             0             0             0             0   \n",
      "Actual 26             0             0             0             0   \n",
      "Actual 32             0             0             1             0   \n",
      "Actual 36             0             0             0             0   \n",
      "\n",
      "           Predicted 32  Predicted 36  \n",
      "Actual 1              0             0  \n",
      "Actual 2              0             0  \n",
      "Actual 3              0             0  \n",
      "Actual 4              0             0  \n",
      "Actual 5              0             0  \n",
      "Actual 6              0             0  \n",
      "Actual 7              0             0  \n",
      "Actual 8              0             0  \n",
      "Actual 9              0             0  \n",
      "Actual 10             0             0  \n",
      "Actual 11             0             0  \n",
      "Actual 12             0             0  \n",
      "Actual 13             0             0  \n",
      "Actual 14             0             0  \n",
      "Actual 15             0             0  \n",
      "Actual 16             0             0  \n",
      "Actual 17             0             0  \n",
      "Actual 18             0             0  \n",
      "Actual 19             0             0  \n",
      "Actual 20             0             0  \n",
      "Actual 21             0             0  \n",
      "Actual 22             0             0  \n",
      "Actual 23             0             0  \n",
      "Actual 24             0             0  \n",
      "Actual 25             0             0  \n",
      "Actual 26             0             0  \n",
      "Actual 32             0             0  \n",
      "Actual 36             0             0  \n",
      "\n",
      "[28 rows x 28 columns]\n",
      "Accuracy Score: 0.7771043771043771\n"
     ]
    }
   ],
   "source": [
    "# y_pred = pipeline.predict(X_test)\n",
    "# # Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_rf_pred)\n",
    "unique_classes = sorted(set(y_test) | set(y_rf_pred))\n",
    "index_labels = [f\"Actual {cls}\" for cls in unique_classes]\n",
    "column_labels = [f\"Predicted {cls}\" for cls in unique_classes]\n",
    "cm_df = pd.DataFrame(cm, index=index_labels, columns=column_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)\n",
    "acc_score = accuracy_score(y_test, y_rf_pred)\n",
    "# # Display the accuracy score\n",
    "print(\"Accuracy Score:\", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old\n",
    "\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# # Calculate the confusion matrix\n",
    "# cm = confusion_matrix(y_test_array, y_pred)\n",
    "# # values in y_test\n",
    "# unique_values = np.unique(np.concatenate((y_test_array, y_pred)))\n",
    "# index_and_columns = [f\"Actual {val}\" for val in unique_values] + [f\"Predicted {val}\" for val in unique_values]\n",
    "# cm_df = pd.DataFrame(cm, index=index_and_columns[:len(unique_values)], columns=index_and_columns[len(unique_values):])\n",
    "# # Display the confusion matrix\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm_df)\n",
    "# # Calculate the accuracy score\n",
    "# acc_score = accuracy_score(y_test_array, y_pred)\n",
    "# # Display the accuracy score\n",
    "# print(\"Accuracy Score:\", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most recent \n",
    "\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# # Calculate the confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# unique_classes = sorted(set(y_test_array) | set(y_pred))\n",
    "# index_labels = [f\"Actual {cls}\" for cls in unique_classes]\n",
    "# column_labels = [f\"Predicted {cls}\" for cls in unique_classes]\n",
    "# cm_df = pd.DataFrame(cm, index=index_labels, columns=column_labels)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm_df)\n",
    "# acc_score = accuracy_score(y_test_array, y_pred)\n",
    "# # Display the accuracy score\n",
    "# print(\"Accuracy Score:\", acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 400, 600, 800]\n",
      "1485\n",
      "Mean Squared Error: 1.5218855218855218\n",
      "Accuracy Score: 0.773063973063973\n",
      "1485\n",
      "Mean Squared Error: 1.5185185185185186\n",
      "Accuracy Score: 0.7656565656565657\n",
      "1485\n",
      "Mean Squared Error: 1.5474747474747474\n",
      "Accuracy Score: 0.7622895622895622\n",
      "1485\n",
      "Mean Squared Error: 1.5454545454545454\n",
      "Accuracy Score: 0.7616161616161616\n"
     ]
    }
   ],
   "source": [
    "#n_est = list(10**i for i in range(3, 6))\n",
    "n_est = list(range(200, 1000, 200))\n",
    "print(n_est)\n",
    "\n",
    "for n in n_est:\n",
    "    rf_model_o = RandomForestRegressor(random_state=42, n_estimators=n)   # default n_estimators=100 \n",
    "    \n",
    "    # Train the model\n",
    "    rf_model_o.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_rfo_pred = rf_model_o.predict(X_test_scaled).astype(\"int\")\n",
    "    print(len(y_rfo_pred))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_o = mean_squared_error(y_test, y_rfo_pred)\n",
    "    print(\"Mean Squared Error:\", mse_o)\n",
    "\n",
    "    acc_score_o = accuracy_score(y_test, y_rfo_pred)\n",
    "    # # Display the accuracy score\n",
    "    print(\"Accuracy Score:\", acc_score_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 40, 60, 80]\n",
      "20\n",
      "Mean Squared Error: 1.5286195286195285\n",
      "Accuracy Score: 0.7838383838383839 \n",
      "\n",
      "\n",
      "40\n",
      "Mean Squared Error: 1.4915824915824916\n",
      "Accuracy Score: 0.7858585858585858 \n",
      "\n",
      "\n",
      "60\n",
      "Mean Squared Error: 1.488888888888889\n",
      "Accuracy Score: 0.7858585858585858 \n",
      "\n",
      "\n",
      "80\n",
      "Mean Squared Error: 1.5104377104377105\n",
      "Accuracy Score: 0.7791245791245791 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = list(range(20, 100, 20))\n",
    "print(n_est)\n",
    "\n",
    "for n in n_est:\n",
    "    print(n)\n",
    "    rf_model_o = RandomForestRegressor(random_state=42, n_estimators=n)   # default n_estimators=100 \n",
    "    \n",
    "    # Train the model\n",
    "    rf_model_o.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_rfo_pred = rf_model_o.predict(X_test_scaled).astype(\"int\")\n",
    "    #print(len(y_rfo_pred))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_o = mean_squared_error(y_test, y_rfo_pred)\n",
    "    print(\"Mean Squared Error:\", mse_o)\n",
    "\n",
    "    acc_score_o = accuracy_score(y_test, y_rfo_pred)\n",
    "    # # Display the accuracy score\n",
    "    print(\"Accuracy Score:\", acc_score_o, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 40, 60, 80, 100] \n",
      "\n",
      "20 bootstrap=False\n",
      "Mean Squared Error: 1.9562289562289563\n",
      "Accuracy Score: 0.7952861952861953 \n",
      "\n",
      "40 bootstrap=False\n",
      "Mean Squared Error: 1.956902356902357\n",
      "Accuracy Score: 0.7946127946127947 \n",
      "\n",
      "60 bootstrap=False\n",
      "Mean Squared Error: 1.967003367003367\n",
      "Accuracy Score: 0.7946127946127947 \n",
      "\n",
      "80 bootstrap=False\n",
      "Mean Squared Error: 1.967003367003367\n",
      "Accuracy Score: 0.7946127946127947 \n",
      "\n",
      "100 bootstrap=False\n",
      "Mean Squared Error: 1.967003367003367\n",
      "Accuracy Score: 0.7946127946127947 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = list(range(20, 120, 20))\n",
    "print(n_est, \"\\n\")\n",
    "\n",
    "for n in n_est:\n",
    "    print(n, \"bootstrap=False\")\n",
    "    rf_model_o = RandomForestRegressor(random_state=42, n_estimators=n, bootstrap=False)   # default n_estimators=100, bootstrap=True\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model_o.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_rfo_pred = rf_model_o.predict(X_test_scaled).astype(\"int\")\n",
    "    #print(len(y_rfo_pred))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_o = mean_squared_error(y_test, y_rfo_pred)\n",
    "    print(\"Mean Squared Error:\", mse_o)\n",
    "\n",
    "    acc_score_o = accuracy_score(y_test, y_rfo_pred)\n",
    "    # # Display the accuracy score\n",
    "    print(\"Accuracy Score:\", acc_score_o, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['squared_error', 'friedman_mse', 'poisson', 'absolute_error'] \n",
      "\n",
      "squared_error\n",
      "Mean Squared Error: 1.5239057239057239\n",
      "Accuracy Score: 0.7771043771043771 \n",
      "\n",
      "friedman_mse\n",
      "Mean Squared Error: 1.5427609427609428\n",
      "Accuracy Score: 0.7784511784511785 \n",
      "\n",
      "poisson\n",
      "Mean Squared Error: 1.5245791245791245\n",
      "Accuracy Score: 0.767003367003367 \n",
      "\n",
      "absolute_error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m rf_model_o \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, criterion\u001b[38;5;241m=\u001b[39mc)   \u001b[38;5;66;03m# default n_estimators=100, bootstrap=True, criterion=\"squared_error\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m rf_model_o\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m y_rfo_pred \u001b[38;5;241m=\u001b[39m rf_model_o\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aleito\\anaconda3\\envs\\data\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criteria = [\"squared_error\", \"friedman_mse\", \"poisson\", \"absolute_error\"]\n",
    "print(criteria, \"\\n\")\n",
    "\n",
    "for c in criteria:\n",
    "    print(c)\n",
    "    rf_model_o = RandomForestRegressor(random_state=42, criterion=c)   # default n_estimators=100, bootstrap=True, criterion=\"squared_error\"\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model_o.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_rfo_pred = rf_model_o.predict(X_test_scaled).astype(\"int\")\n",
    "    #print(len(y_rfo_pred))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_o = mean_squared_error(y_test, y_rfo_pred)\n",
    "    print(\"Mean Squared Error:\", mse_o)\n",
    "\n",
    "    acc_score_o = accuracy_score(y_test, y_rfo_pred)\n",
    "    # # Display the accuracy score\n",
    "    print(\"Accuracy Score:\", acc_score_o, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
